{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc33802d",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "Our community is often confronted with the need of running complex algorithms for a set of different input.\n",
    "E.g. a DA computation with tune scan + beam-beam + errors.\n",
    "\n",
    "This implies to stage the algorithm in different steps corresponding, sometimes, to different codes (MADX, SixTrack,...) and/or different hardware (local CPU, GPU, HTCondor/LSF clusters, BOINC...).\n",
    "\n",
    "The topic of this brainstorming is to discuss about a python package that could convey a **standard** approach in order to\n",
    "\n",
    "- avoid re-inventing the wheel each time, \n",
    "- improve the way we share our work-flow for the different simulations,\n",
    "- provide a standard way to babysitting the simulations and postprocess the output.\n",
    "\n",
    "Clearly the package can be integrated with other solutions (see next [presentation]()).\n",
    "\n",
    "The challenge here is to maintain a good balance between simplicity (to be user-friendly) and flexibility (to cover a large gamut of use cases).\n",
    "\n",
    "You can find at https://gitlab.cern.ch/abpcomputing/sandbox/tree_maker a proposal.\n",
    "We are going first to present its rationale (a bit abstract, 5 min) and then explore together a simple example (pragmatic and complementary to the first part, 15 min).\n",
    "\n",
    "\n",
    "### Rationale\n",
    "\n",
    "The general way to describe our problem (running a staged algorithm for a set of different input) is to associate a **job** for each stage and input.\n",
    "\n",
    "A job can be represented as a **node** in a **graph** (nodes connected with edges).\n",
    " \n",
    "The main idea is to downscale the problem of a generic graph to a simpler graph, a **tree**.\n",
    "\n",
    "A **tree** is a simplified **DAG** (Directed Acycled Graphs) where each node can have maximum one parent.\n",
    "The tree is convenient since it can be directly mapped into a file system (the folder stucture of a file system is a tree).\n",
    "\n",
    "In python a tree can be represented, for example, with the `anytree` package (see [000_example](https://gitlab.cern.ch/abpcomputing/sandbox/tree_maker/-/blob/master/examples/000_example/000.ipynb)). \n",
    "\n",
    "The `anynode` object of the `anytree` package can be generalized to any class.\n",
    "Indeed we generalized it to our `NodeJob` class, inheriting all the methods/attributes of `anynode`, e.g., root, parent, children, ancestors, siblings, leaves, depth, height, searching/filtering methods... \n",
    "\n",
    "The main ideas is that each node of our simulation tree \n",
    "\n",
    "1. is a instance of the `NodeJob` (extending the `anytree`).\n",
    "2. refers to a **template node** (example a MadX mask): `NodeJob.template_path`\n",
    "3. has a specific dictionary of input, `NodeJob.dictionary`\n",
    "4. is mapped to a file system, `NodeJob.path`\n",
    "5. has a specific submit command, `NodeJob.submit_command`\n",
    "6. has a specific log file, `NodeJob.log_path`\n",
    "\n",
    "\n",
    "In this way we can factorize the physics (the template), the parameters (the dictionary), the folder (JobNode.path) but maintaining for all nodes the very same interface (`JobNode`).\n",
    "\n",
    "The users should spend 99% of their time on the physics (the templates), and use the package to build/orchestrate the tree.\n",
    "\n",
    "#### Building of the tree\n",
    "The building of the tree is done in three steps:\n",
    "- istantiating the nodes\n",
    "- **cloning** (i.e. copying) the templates on the NodeJob.path\n",
    "- **mutating** (i.e. changing) the input of the template with the info in the NodeJob.dictionary\n",
    "\n",
    "\n",
    "#### Orchestrating the tree\n",
    "\n",
    "Each node can be run (refers to NodeJob.submit_command) and logged (NodeJob.submit_command).\n",
    "One can orchestrate the simulation but writing and reading in the different log.\n",
    "\n",
    "We will show now a simple example to clarify all these ingredients.\n",
    "\n",
    "\n",
    "\n",
    "### Simple example ([001_example](https://gitlab.cern.ch/abpcomputing/sandbox/tree_maker/-/blob/master/examples/001_example/001.ipynb))\n",
    "\n",
    "\n",
    "Let aussume that we need to make this computation\n",
    "\n",
    "$\\sqrt{|(a+b)\\times c|}$\n",
    "\n",
    "and we want to compute the standard deviation of the result assuming that a, b and c are normal distributed independent variables. Clearly the problem is quite naive but we want to address it as if we will need a cluster to solve it. \n",
    "\n",
    "For example, we can partition the problem in three conscutive stages\n",
    "\n",
    "1. A sum: $(a+b)$\n",
    "2. A multiplication of the result 1 with c: $(a+b)\\times c$\n",
    "3. A sqrt of the result of 2: $\\sqrt{|(a+b)\\times c|}$\n",
    "\n",
    "For each stage we build a template.\n",
    "Documentation (only started, you need to be on GPN) can be found at https://acc-py.web.cern.ch/gitlab/abpcomputing/sandbox/tree_maker/docs/master/. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0df4bfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tree_maker\n",
    "from tree_maker import NodeJob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "97a88117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clearly for this easy task on can do all in the very same python kernel\n",
    "# BUT here we want to mimic the typical flow\n",
    "# 1. MADX for optics matching/error seeding\n",
    "# 2. Tracking for FMA and or DA studies\n",
    "# 3. simulation baby-sitting and\n",
    "# 4. postprocessing\n",
    "\n",
    "import numpy as np\n",
    "a=np.random.randn(4)\n",
    "b=np.random.randn(4)\n",
    "c=np.random.randn(2)\n",
    "\n",
    "my_list_original=[]\n",
    "for ii in c:\n",
    "    my_list_original+=list(np.sqrt(np.abs((a+b)*ii)))\n",
    "my_list_original=sorted(my_list_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54554408",
   "metadata": {},
   "source": [
    "#### The root of the tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f4d2df7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#root\n",
    "root = NodeJob(name='root', parent=None)\n",
    "root.path = '/home/jovyan/local_host_home/CERNBox/2021/tree_maker/examples/001_example/study_000'\n",
    "root.template_path = root.path + '/../templates'\n",
    "root.log_file = root.path + \"/log.yaml\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c372b59e",
   "metadata": {},
   "source": [
    "#### First generation of nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7b62b304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      "├── 000\n",
      "├── 001\n",
      "├── 002\n",
      "╰── 003\n"
     ]
    }
   ],
   "source": [
    "#first generation\n",
    "for node in root.root.generation(0):\n",
    "    node.children=[NodeJob(name=f\"{child:03}\",\n",
    "                           parent=node,\n",
    "                           path=f\"{node.path}/{child:03}\",\n",
    "                           template_path = root.template_path+'/sum_it',\n",
    "                           submit_command = f'python run.py',\n",
    "                           log_file=f\"{node.path}/{child:03}/log.yaml\",\n",
    "                           dictionary={'a':float(a[child]), \n",
    "                                       'b':float(b[child])\n",
    "                                      })\n",
    "                   for child in range(len(a))]\n",
    "\n",
    "# To combine different lists one can use the product or the zip functions    \n",
    "#import itertools\n",
    "#[[i, j, z] for i, j, z in itertools.product(['a','b'],['c','d'],[1,2,3])]\n",
    "#[[i, j, z] for i, j, z in zip(['a','b'],['c','d'],[1,2,3])]\n",
    "root.print_it()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0a877c",
   "metadata": {},
   "source": [
    "#### Second generation of nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b5234f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      "├── 000\n",
      "│   ├── 000\n",
      "│   ╰── 001\n",
      "├── 001\n",
      "│   ├── 000\n",
      "│   ╰── 001\n",
      "├── 002\n",
      "│   ├── 000\n",
      "│   ╰── 001\n",
      "╰── 003\n",
      "    ├── 000\n",
      "    ╰── 001\n"
     ]
    }
   ],
   "source": [
    "#second generation\n",
    "for node in root.root.generation(1):\n",
    "    node.children=[NodeJob(name=f\"{child:03}\",\n",
    "                           parent=node,\n",
    "                           path = f\"{node.path}/{child:03}\",\n",
    "                           template_path = root.template_path+'/multiply_it',\n",
    "                           submit_command = f'python run.py',\n",
    "                           log_file=f\"{node.path}/{child:03}/log.yaml\",\n",
    "                           dictionary={'c': float(c[child])})\n",
    "                   for child in range(len(c))]\n",
    "root.print_it()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1656c5e6",
   "metadata": {},
   "source": [
    "#### Third generation of nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ff460439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      "├── 000\n",
      "│   ├── 000\n",
      "│   │   ╰── 000\n",
      "│   ╰── 001\n",
      "│       ╰── 000\n",
      "├── 001\n",
      "│   ├── 000\n",
      "│   │   ╰── 000\n",
      "│   ╰── 001\n",
      "│       ╰── 000\n",
      "├── 002\n",
      "│   ├── 000\n",
      "│   │   ╰── 000\n",
      "│   ╰── 001\n",
      "│       ╰── 000\n",
      "╰── 003\n",
      "    ├── 000\n",
      "    │   ╰── 000\n",
      "    ╰── 001\n",
      "        ╰── 000\n"
     ]
    }
   ],
   "source": [
    "#third generation\n",
    "for node in root.root.generation(2):\n",
    "    node.children=[NodeJob(name=f\"{child:03}\",\n",
    "                           parent=node, \n",
    "                           path = f\"{node.path}/{child:03}\",\n",
    "                           template_path = root.template_path+'/square_root_it',\n",
    "                           submit_command = f'python run.py',\n",
    "                           log_file=f\"{node.path}/{child:03}/log.yaml\",\n",
    "                           dictionary={'log_file': f\"{node.path}/{child:03}/log.yaml\"})\n",
    "                           for child in range(1)]\n",
    "root.print_it()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "929dd35f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'python run.py'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can inspect the data structure\n",
    "root.children[3].children[1].children[0].submit_command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "316735a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# or we can modify the attributes of the tree\n",
    "if False:\n",
    "    for i, node in enumerate(root.leaves):\n",
    "        if i>3:\n",
    "            print(i)\n",
    "            node.submit_command = f'condor_submit run.sub -batch-name square_root'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "94f95902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can transfer the information of the tree in a yaml for the orchestration later\n",
    "root.to_yaml()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7348bdc",
   "metadata": {},
   "source": [
    "### Cloning the templates of the nodes\n",
    "From python objects we move the nodes to the file-system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5517d98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We map the pythonic tree in a >folder< tree\n",
    "root.clean_log()\n",
    "root.rm_children_folders()\n",
    "for depth in range(root.height):\n",
    "    [x.clone_children() for x in root.generation(depth)]\n",
    "\n",
    "# VERY IMPORTANT, tagging\n",
    "root.tag_as('cloned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f94cc59",
   "metadata": {},
   "source": [
    "### Launching the jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2bfd5442",
   "metadata": {},
   "outputs": [],
   "source": [
    "root.tag_as('launched')\n",
    "for node in root.generation(1):\n",
    "    node.cleanlog_mutate_submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "61daaf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in root.generation(2):\n",
    "    node.cleanlog_mutate_submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fcd92d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in root.generation(3):\n",
    "    node.cleanlog_mutate_submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "60197db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All jobs are completed!\n"
     ]
    }
   ],
   "source": [
    "# check if all root descendants are completed \n",
    "if all([descendant.has_been('completed') for descendant in root.descendants]):\n",
    "    root.tag_as('completed')\n",
    "    print('All jobs are completed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1679f68c",
   "metadata": {},
   "source": [
    "### Post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f5bbc785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the output\n",
    "my_list=[]\n",
    "for node in root.leaves:\n",
    "    output = tree_maker.from_yaml(node.path+'/output.yaml')\n",
    "    my_list.append(output['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "601e756a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "assert any(np.array(sorted(my_list))-np.array(my_list_original))==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4759a59b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40196317514377394"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# std of the results\n",
    "np.std(my_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d31da8",
   "metadata": {},
   "source": [
    "### Monitoring "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6ca20c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "root=tree_maker.tree_from_yaml(f'/home/jovyan/local_host_home/CERNBox/2021/tree_maker/examples/001_example/study_000/tree.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "bee058fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/local_host_home/CERNBox/2021/tree_maker/examples/001_example/study_000/000\n",
      "/home/jovyan/local_host_home/CERNBox/2021/tree_maker/examples/001_example/study_000/001\n",
      "/home/jovyan/local_host_home/CERNBox/2021/tree_maker/examples/001_example/study_000/002\n",
      "/home/jovyan/local_host_home/CERNBox/2021/tree_maker/examples/001_example/study_000/003\n"
     ]
    }
   ],
   "source": [
    "# checking the status\n",
    "for node in root.find(filter_= lambda node: node.depth==1 and \n",
    "                                   node.has_been('completed')):\n",
    "    print(node.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "342f1b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/local_host_home/CERNBox/2021/tree_maker/examples/001_example/study_000/002/000/000\n",
      "/home/jovyan/local_host_home/CERNBox/2021/tree_maker/examples/001_example/study_000/002/001/000\n",
      "/home/jovyan/local_host_home/CERNBox/2021/tree_maker/examples/001_example/study_000/003/000/000\n"
     ]
    }
   ],
   "source": [
    "def my_test(node):\n",
    "    output = tree_maker.from_yaml(node.path+'/output.yaml')\n",
    "    return output['result']<1.2\n",
    "\n",
    "for node in root.find(filter_=lambda node: node.is_leaf and \n",
    "                                           node.has_been('completed') and \n",
    "                                           my_test(node)):\n",
    "    print(node.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c93a703a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\n"
     ]
    }
   ],
   "source": [
    "a=np.array([3])\n",
    "b=a.copy()\n",
    "b[0]=2\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "20931e84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'13'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'1'+'3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dda51e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
